{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "\n",
    "from os import listdir\n",
    "from pickle import dump, load\n",
    "\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "import keras\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "#from keras.preprocessing.text import Tokenizerb\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers.merge import add\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense, LSTM, Embedding, Dropout\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(filename):\n",
    "    model = VGG16()  \n",
    "    print(model.summary())\n",
    "    model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
    "    print(model.summary())\n",
    "    image = load_img(filename, target_size=(224, 224))\n",
    "    image = img_to_array(image)\n",
    "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "    image = preprocess_input(image)\n",
    "    feature = model.predict(image, verbose=0)\n",
    "    return feature\n",
    "\n",
    "def word_for_id(integer, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == integer:\n",
    "            return word\n",
    "    return None\n",
    "\n",
    "def generate_desc(model, tokenizer, photo, max_length):\n",
    "    in_text = 'startseq'\n",
    "    for i in range(max_length):\n",
    "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
    "        yhat = model.predict([photo,sequence], verbose=0)\n",
    "        print(yhat)\n",
    "        yhat = argmax(yhat)\n",
    "        word = word_for_id(yhat, tokenizer)\n",
    "        if word is None:\n",
    "            break\n",
    "        in_text += ' ' + word\n",
    "        if word == 'endseq':\n",
    "            break\n",
    "    return in_text\n",
    "\n",
    "tokenizer = load(open('tokenizer.pkl', 'rb'))\n",
    "max_length = 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(r'F:\\Venkatesh\\PROJECTS\\Image Caption Generator\\Training\\models\\model_6.h5')\n",
    "path = r'F:\\Venkatesh\\PROJECTS\\Image Caption Generator\\Flask\\uploads\\47871819_db55ac4699.jpg'\n",
    "photo = extract_features(path)\n",
    "\n",
    "description = generate_desc(model, tokenizer, photo, max_length)\n",
    "print(description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"gTTS==2.1.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gTTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required module for text \n",
    "# to speech conversion\n",
    "#import gTTS\n",
    "#from gtts import *\n",
    "#from gtts import gTTS \n",
    "\n",
    "from gtts import gTTS\n",
    "\n",
    "# This module is imported so that we can \n",
    "# play the converted audio\n",
    "import os\n",
    "  \n",
    "# The text that you want to convert to audio\n",
    "mytext = description\n",
    "  \n",
    "# Language in which you want to convert\n",
    "language = 'en'\n",
    "  \n",
    "# Passing the text and language to the engine, \n",
    "# here we have marked slow=False. Which tells \n",
    "# the module that the converted audio should \n",
    "# have a high speed\n",
    "myobj = gTTS(text=mytext, lang=language, slow=False)\n",
    "  \n",
    "# Saving the converted audio in a mp3 file named\n",
    "# welcome \n",
    "myobj.save(\"welcome.mp3\")\n",
    "  \n",
    "# Playing the converted file\n",
    "os.system(\"mpg321 welcome.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [04/Nov/2021 17:26:48] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [04/Nov/2021 17:26:48] \"\u001b[37mGET /static/css/main.css HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [04/Nov/2021 17:26:48] \"\u001b[37mGET /static/js/main.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [04/Nov/2021 17:26:51] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current path\n",
      "current path \n",
      "upload folder is  uploads\\109202756_b97fcdc62c.jpg\n",
      "model loaded\n",
      "features extracted\n",
      "image loaded\n",
      "[[[211. 224. 241.]\n",
      "  [212. 225. 242.]\n",
      "  [212. 225. 242.]\n",
      "  ...\n",
      "  [121. 121. 113.]\n",
      "  [145. 144. 149.]\n",
      "  [221. 227. 227.]]\n",
      "\n",
      " [[211. 224. 241.]\n",
      "  [211. 224. 241.]\n",
      "  [211. 224. 241.]\n",
      "  ...\n",
      "  [100. 101. 103.]\n",
      "  [121. 122. 142.]\n",
      "  [240. 239. 255.]]\n",
      "\n",
      " [[211. 224. 241.]\n",
      "  [211. 224. 241.]\n",
      "  [211. 224. 241.]\n",
      "  ...\n",
      "  [110. 116. 104.]\n",
      "  [205. 206. 200.]\n",
      "  [ 81.  71.  95.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[179. 160. 153.]\n",
      "  [166. 158. 137.]\n",
      "  [127. 114. 105.]\n",
      "  ...\n",
      "  [232. 236. 248.]\n",
      "  [226. 230. 242.]\n",
      "  [228. 232. 244.]]\n",
      "\n",
      " [[102.  83.  79.]\n",
      "  [100.  85.  78.]\n",
      "  [189. 167. 169.]\n",
      "  ...\n",
      "  [229. 233. 244.]\n",
      "  [231. 235. 246.]\n",
      "  [230. 234. 245.]]\n",
      "\n",
      " [[ 74.  61.  52.]\n",
      "  [ 55.  47.  36.]\n",
      "  [129. 114. 111.]\n",
      "  ...\n",
      "  [229. 233. 244.]\n",
      "  [230. 234. 245.]\n",
      "  [230. 234. 245.]]]\n",
      "model predicted\n",
      "generate description\n",
      "sequence\n",
      "[[8.8604670e-09 8.8005914e-09 1.8135086e-05 ... 8.6416057e-09\n",
      "  2.9506666e-07 1.4755507e-07]]\n",
      "dog\n",
      "sequence\n",
      "[[3.4301229e-10 3.5300404e-10 1.0762583e-03 ... 3.4607597e-10\n",
      "  1.5531109e-11 1.1751639e-11]]\n",
      "is\n",
      "sequence\n",
      "[[4.9722483e-11 4.5827384e-11 1.2820958e-05 ... 4.7086630e-11\n",
      "  2.4743090e-16 1.9598210e-15]]\n",
      "running\n",
      "sequence\n",
      "[[1.1791280e-09 1.1991000e-09 3.5366695e-02 ... 1.1708694e-09\n",
      "  3.0930972e-12 3.1606270e-11]]\n",
      "through\n",
      "sequence\n",
      "[[4.6653468e-09 5.1646980e-09 9.5874475e-06 ... 5.2966027e-09\n",
      "  1.5443388e-13 3.9897001e-12]]\n",
      "the\n",
      "sequence\n",
      "[[1.8987192e-09 1.9875874e-09 4.7447170e-06 ... 2.0114079e-09\n",
      "  5.4988512e-14 3.8295916e-12]]\n",
      "grass\n",
      "sequence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [04/Nov/2021 17:28:00] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.1363030e-11 3.2993667e-11 4.0966210e-01 ... 3.0075244e-11\n",
      "  8.9256064e-18 3.7041103e-16]]\n",
      "endseq\n",
      "startseq dog is running through the grass endseq\n"
     ]
    }
   ],
   "source": [
    "from pickle import load\n",
    "from numpy import argmax\n",
    "import argparse\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "import os\n",
    "from flask import Flask , request, render_template\n",
    "from werkzeug.utils import secure_filename\n",
    "from gevent.pywsgi import WSGIServer\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "@app.route('/predict',methods = ['GET','POST'])\n",
    "def upload():\n",
    "    if request.method == 'POST':\n",
    "        f = request.files['image']\n",
    "        print(\"current path\")\n",
    "        basepath = os.path.dirname(\"__file__\")\n",
    "        print(\"current path\", basepath)\n",
    "        filepath = os.path.join(basepath,'uploads',f.filename)\n",
    "        print(\"upload folder is \", filepath)\n",
    "        f.save(filepath)\n",
    "        text = modelpredict(filepath)\n",
    "        return text\n",
    "def extract_features(filename):\n",
    "    print('features extracted')\n",
    "    model = VGG16()\n",
    "    #model.layers.pop()\n",
    "    model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
    "    image = load_img(filename, target_size=(224, 224))\n",
    "    print('image loaded')\n",
    "    image = img_to_array(image)\n",
    "    print(image)\n",
    "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "    image = preprocess_input(image)\n",
    "    feature = model.predict(image, verbose=0)\n",
    "    print('model predicted')\n",
    "    return feature\n",
    "def word_for_id(integer, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == integer:\n",
    "            return word\n",
    "    return None\n",
    "def generate_desc(model, tokenizer, photo, max_length):\n",
    "    print(\"generate description\")\n",
    "    in_text = 'startseq'\n",
    "    for i in range(max_length):\n",
    "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
    "        print('sequence')\n",
    "        yhat = model.predict([photo,sequence], verbose=0)\n",
    "        print(yhat)\n",
    "        yhat = argmax(yhat)\n",
    "        word = word_for_id(yhat, tokenizer)\n",
    "        print(word)\n",
    "        if word is None:\n",
    "            break\n",
    "        in_text += ' ' + word\n",
    "        if word == 'endseq':\n",
    "            break\n",
    "    print(in_text)\n",
    "    return in_text\n",
    " \n",
    "def modelpredict(filepath):\n",
    "    tokenizer = load(open(r'F:\\Venkatesh\\PROJECTS\\Image Caption Generator\\tokenizer.pkl', 'rb'))\n",
    "    max_length = 34\n",
    "    model = load_model(r'F:\\Venkatesh\\PROJECTS\\Image Caption Generator\\model_18.h5')\n",
    "    print('model loaded')\n",
    "    photo = extract_features(filepath)\n",
    "    description = generate_desc(model, tokenizer, photo, max_length)\n",
    "    return description\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!{sys.executable} -m pip install gevent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from flask import Flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
